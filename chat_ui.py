import streamlit as st
import os
from dotenv import load_dotenv
from openai import OpenAI
from sentence_transformers import SentenceTransformer
import faiss, pickle

# Load env
load_dotenv()
client = OpenAI(api_key=os.getenv("GROQ_API_KEY"), base_url="https://api.groq.com/openai/v1")

# Load FAISS index + metadata
embedder = SentenceTransformer("all-MiniLM-L6-v2")
INDEX_PATH = "faiss.index"
META_PATH = "meta.pkl"

if os.path.exists(INDEX_PATH) and os.path.exists(META_PATH):
    index = faiss.read_index(INDEX_PATH)
    with open(META_PATH, "rb") as f:
        metadata = pickle.load(f)
else:
    st.error("‚ö†Ô∏è No FAISS index found. Please upload documents and build index.")
    st.stop()

def query_rag(query, top_k=3):
    q_emb = embedder.encode([query], convert_to_numpy=True)
    D, I = index.search(q_emb, top_k)
    docs = []
    for idx in I[0]:
        if idx < len(metadata):
            docs.append(metadata[idx])
    return docs

def generate_answer(user_message: str, context_docs: list = []):
    context_text = "\n\n".join([f"SOURCE: {d['source']}\n{d['text']}" for d in context_docs])
    response = client.chat.completions.create(
        model="llama-3.1-8b-instant",
        messages=[
            {"role": "system", "content": "You are Mandi Sahayak Assistant. Reply in Hindi or English based only on context docs."},
            {"role": "user", "content": f"Context:\n{context_text}\n\nUser: {user_message}"}
        ],
        temperature=0.2,
        max_tokens=500
    )
    return response.choices[0].message.content

# Streamlit UI
st.set_page_config(page_title="Mandi Sahayk Chatbot", page_icon="üåæ")
st.title("Mandi Sahayk Agentic AI Chatbot")
st.caption("Get answers from the APMC Act 2020 and mandi rules.")

# Default welcome message
WELCOME_MESSAGE = (
    "üëã **‡§®‡§Æ‡§∏‡•ç‡§§‡•á ‡§ï‡§ø‡§∏‡§æ‡§® ‡§≠‡§æ‡§à!**\n\n"
    "‡§Æ‡•à‡§Ç *‡§Æ‡§Ç‡§°‡•Ä ‡§∏‡§π‡§æ‡§Ø‡§ï ‡§ö‡•à‡§ü‡§¨‡•ã‡§ü* ‡§π‡•Ç‡§Å‡•§ ‡§Æ‡•à‡§Ç ‡§Ü‡§™‡§ï‡•Ä ‡§Æ‡§¶‡§¶ ‡§ï‡§∞ ‡§∏‡§ï‡§§‡§æ ‡§π‡•Ç‡§Å:\n"
    "- APMC Act 2020 ‡§∏‡•á ‡§ú‡•Å‡§°‡§º‡•á ‡§∏‡§µ‡§æ‡§≤‡•ã‡§Ç ‡§Æ‡•á‡§Ç\n"
    "- ‡§Æ‡§Ç‡§°‡•Ä ‡§≤‡§æ‡§á‡§∏‡•á‡§Ç‡§∏ ‡§™‡•ç‡§∞‡§ï‡•ç‡§∞‡§ø‡§Ø‡§æ\n"
    "- ‡§µ‡•ç‡§Ø‡§æ‡§™‡§æ‡§∞‡•Ä ‡§™‡§Ç‡§ú‡•Ä‡§ï‡§∞‡§£ ‡§®‡§ø‡§Ø‡§Æ\n"
    "- ‡§´‡§∏‡§≤ ‡§ñ‡§∞‡•Ä‡§¶, ‡§®‡•Ä‡§≤‡§æ‡§Æ‡•Ä ‡§î‡§∞ ‡§∂‡•Å‡§≤‡•ç‡§ï\n"
    "- ‡§ï‡§ø‡§∏‡§æ‡§® ‡§Ö‡§ß‡§ø‡§ï‡§æ‡§∞ ‡§î‡§∞ ‡§∏‡•Å‡§∞‡§ï‡•ç‡§∑‡§æ ‡§™‡•ç‡§∞‡§æ‡§µ‡§ß‡§æ‡§®\n\n"
    "**‡§Ö‡§™‡§®‡§æ ‡§∏‡§µ‡§æ‡§≤ ‡§Ø‡§π‡§æ‡§Å ‡§≤‡§ø‡§ñ‡•á‡§Ç üëá**"
)

if "messages" not in st.session_state:
    st.session_state.messages = [
        {"sender": "bot", "text": WELCOME_MESSAGE}
    ]

# Show messages
for msg in st.session_state.messages:
    if msg["sender"] == "user":
        st.chat_message("user").markdown(msg["text"])
    else:
        st.chat_message("assistant").markdown(msg["text"])
        if "sources" in msg and msg["sources"]:
            st.caption(f"üìÑ ‡§∏‡•ç‡§∞‡•ã‡§§: {', '.join(msg['sources'])}")

# Input box
if user_input := st.chat_input("‡§Ö‡§™‡§®‡§æ ‡§∏‡§µ‡§æ‡§≤ ‡§≤‡§ø‡§ñ‡•á‡§Ç..."):
    st.session_state.messages.append({"sender": "user", "text": user_input})
    st.chat_message("user").markdown(user_input)

    docs = query_rag(user_input, top_k=3)
    answer = generate_answer(user_input, docs)
    sources = [d["source"] for d in docs]

    st.session_state.messages.append({"sender": "bot", "text": answer, "sources": sources})
    st.chat_message("assistant").markdown(answer)
    if sources:
        st.caption(f"üìÑ Sources: {', '.join(sources)}")
